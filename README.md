# Student-Performance-Regression

üß† **Objetivo: Predicci√≥n de la nota media de los estudiantes**

## üìå Descripci√≥n general

Este proyecto tiene como objetivo desarrollar y evaluar modelos de **regresi√≥n** que permitan predecir la **nota media (`average_score`)** de un estudiante a partir de sus caracter√≠sticas personales y acad√©micas.

La nota media se ha construido como la media de tres puntuaciones originales del dataset:

- `math score`
- `reading score`
- `writing score`

A partir de esta nueva variable objetivo (`average_score`), se entrena un modelo capaz de estimar el rendimiento acad√©mico global del alumno.

---

## üìä Dataset

El conjunto de datos contiene **1.000 estudiantes**, con la siguiente informaci√≥n principal:

- `gender`  
- `race/ethnicity`  
- `parental level of education`  
- `lunch`  
- `test preparation course`  
- `math score`, `reading score`, `writing score`

A partir de estas tres √∫ltimas se crea el atributo:

- `average_score` ‚Üí objetivo a predecir.

No se han encontrado valores nulos en ninguna columna, por lo que no ha sido necesario aplicar t√©cnicas de imputaci√≥n.

---

## üîç Enfoque del proyecto

### 1. An√°lisis exploratorio

- An√°lisis descriptivo de las notas (`math`, `reading`, `writing`) y de `average_score`.
- Estudio de la distribuci√≥n de las variables categ√≥ricas:
  - `gender`
  - `race/ethnicity`
  - `parental level of education`
  - `lunch`
  - `test preparation course`
- An√°lisis de c√≥mo cambia `average_score` seg√∫n cada variable categ√≥rica (boxplots por grupo).
- Matriz de correlaci√≥n entre todas las variables ya codificadas, incluyendo `average_score`, para comprobar:
  - qu√© atributos se relacionan m√°s con la nota,
  - y si hay correlaciones fuertes entre predictores (redundancias).

### 2. Preprocesamiento

- **Creaci√≥n de la variable objetivo**:  
  `average_score = media(math score, reading score, writing score)`.

- **Tratamiento de valores nulos**:
  - Visualizaci√≥n con `missingno` y recuento con `isnull().sum()`.
  - Se confirma que no hay valores faltantes.

- **Codificaci√≥n de variables categ√≥ricas**:

  - `LabelEncoder` para variables binarias:
    - `gender` (0/1)  
    - `lunch` (0/1)  
    - `test preparation course` (0/1)

  - `OneHotEncoder` para variables con m√°s de dos categor√≠as:
    - `race/ethnicity` (grupos A, B, C, D, E)  
    - `parental level of education` (high school, some college, bachelor‚Äôs, master‚Äôs, etc.)

  De esta forma, todas las variables quedan en formato num√©rico y listas para ser usadas por los modelos.

- **Divisi√≥n entrenamiento / test**:
  - `train_test_split` con un **80 % para entrenamiento** y **20 % para test**.

- **Normalizaci√≥n**:
  - No ha sido necesaria la normalizaci√≥n de variables num√©ricas adicionales, ya que el modelo seleccionado final es una regresi√≥n lineal sobre variables ya escaladas de forma razonable y sin valores extremos.

---

## ü§ñ Modelado y validaci√≥n

Se han entrenado varios modelos de regresi√≥n usando **validaci√≥n cruzada con KFold (k=10)** y las m√©tricas:

- **MAE** (Error Absoluto Medio)  
- **RMSE** (Ra√≠z del Error Cuadr√°tico Medio)  
- **R¬≤** (coeficiente de determinaci√≥n)

Modelos probados:

- `LinearRegression`
- `KNeighborsRegressor`
- `DecisionTreeRegressor`
- `RandomForestRegressor`
- `GradientBoostingRegressor`

Para cada modelo se calculan los valores medios de MAE, RMSE y R¬≤ en los 10 folds.  
Adem√°s, se dibujan **curvas de aprendizaje** (MAE de entrenamiento y de validaci√≥n) para analizar:

- si el modelo sobreajusta o no,
- y c√≥mo mejora el error al aumentar el tama√±o del conjunto de entrenamiento.

---

## üìà Resultados principales

- El modelo que obtiene el **mejor equilibrio** entre error y capacidad de explicaci√≥n es **LinearRegression**.
- En validaci√≥n cruzada:
  - MAE medio ‚âà 10 puntos.
  - RMSE medio ‚âà 12‚Äì13 puntos.
  - R¬≤ medio positivo, mejor que el resto de modelos probados.
- En el conjunto de **test**:
  - **MAE ‚âà 9.8**  
  - **RMSE ‚âà 12.4**  
  - **R¬≤ ‚âà 0.27**

Esto significa que el modelo se equivoca de media unos **10 puntos** sobre una escala de 0 a 100, y es capaz de explicar aproximadamente un **27 %** de la variabilidad de las notas.

Tambi√©n se incluye un **gr√°fico de dispersi√≥n** de:

- `average_score` real (eje X)  
- `average_score` predicho (eje Y)

con una l√≠nea roja `y = x` como referencia. Los puntos se concentran alrededor de esa l√≠nea, sobre todo entre notas medias (50‚Äì80), lo que indica que el modelo sigue bien la tendencia, aunque tiene m√°s dificultad con notas muy bajas o muy altas.

---

## ‚úÖ Conclusiones

- El modelo de **regresi√≥n lineal** ofrece un rendimiento **razonable** y consistente entre validaci√≥n cruzada y test.
- El error medio (MAE) es moderado y el R¬≤ muestra que el modelo captura parte, pero no toda, de la informaci√≥n relevante sobre el rendimiento acad√©mico.
- El modelo funciona especialmente bien para estudiantes con notas medias, y le cuesta m√°s predecir notas extremas (muy bajas o muy altas).

---

## üöÄ Trabajo futuro

Algunas posibles mejoras:

- Incluir **nuevas variables** relacionadas con:
  - h√°bitos de estudio,
  - horas de dedicaci√≥n,
  - asistencia a clase,
  - contexto socioecon√≥mico, etc.
- Probar **modelos m√°s complejos** (p. ej. Random Forest, Gradient Boosting con mejor ajuste) junto con una b√∫squeda sistem√°tica de **hiperpar√°metros** (`GridSearchCV` o `RandomizedSearchCV`).
- Explorar t√©cnicas de **ingenier√≠a de caracter√≠sticas** adicionales:
  - combinaciones de variables,
  - variables agregadas,
  - detecci√≥n y tratamiento m√°s fino de outliers.

---

## üóÇ Estructura del repositorio

- `dataset/` ‚Üí fichero(s) CSV con los datos de estudiantes.  
- `students.ipynb` ‚Üí notebook principal con:
  - an√°lisis exploratorio,
  - preprocesamiento,
  - selecci√≥n de modelos,
  - validaci√≥n cruzada,
  - evaluaci√≥n en test y conclusiones.
- `README.md` ‚Üí este documento.

---

## üíª Tecnolog√≠as utilizadas

- **Python 3**
- **pandas, numpy**
- **seaborn, matplotlib, missingno**
- **scikit-learn** (`LabelEncoder`, `OneHotEncoder`, `LinearRegression`, `KNeighborsRegressor`, `DecisionTreeRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`, `KFold`, `cross_validate`, `learning_curve`, `mean_absolute_error`, `mean_squared_error`, `r2_score`)

